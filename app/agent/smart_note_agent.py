"""
æ™ºèƒ½ç¬”è®° Agent - Plan-and-Execute æ¨¡å¼ï¼Œæ”¯æŒå¤šè½®åæ€
"""
from typing import List, Dict, Optional, Tuple
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from app.tools.analysis_tools import (
    analyze_text_entities,
    get_entity_position,
    suggest_relations,
    analyze_graph_position
)
from app.tools.note_tools import save_note, execute_raw_cypher, get_graph_schema
from config import config


class SmartNoteAgent:
    """
    æ™ºèƒ½ç¬”è®°åŠ©æ‰‹ï¼Œé‡‡ç”¨ Plan-and-Execute æ¨¡å¼

    å·¥ä½œæµç¨‹ï¼š
    1. æ¥æ”¶ç”¨æˆ·è¾“å…¥
    2. åˆ†ææ–‡æœ¬ï¼Œæå–å®ä½“å’Œæ ‡ç­¾
    3. æŸ¥è¯¢å®ä½“çš„ç°æœ‰ä½ç½®
    4. åæ€å’Œè§„åˆ’ï¼šç¡®å®šåº”è¯¥æ”¾åœ¨å“ªé‡Œ
    5. æ‰§è¡Œä¿å­˜æ“ä½œ
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            model=config.LLM_MODEL,
            api_key=config.LLM_API_KEY,
            base_url=config.LLM_BASE_URL,
            temperature=0.7,
        )

        self.tools = [
            analyze_text_entities,
            get_entity_position,
            suggest_relations,
            analyze_graph_position,
            save_note,
            execute_raw_cypher,
            get_graph_schema
        ]

        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ç¬”è®°åŠ©æ‰‹ï¼Œé‡‡ç”¨"å…ˆæ€è€ƒåè¡ŒåŠ¨"çš„å·¥ä½œæ¨¡å¼ã€‚

ä½ çš„å·¥ä½œæµç¨‹ï¼š

1. **ç¬¬1æ­¥ï¼šæå–åˆ†æ**
   - å½“ç”¨æˆ·è¦ä¿å­˜ç¬”è®°æ—¶ï¼Œå…ˆè°ƒç”¨ `analyze_text_entities` åˆ†ææ–‡æœ¬
   - è¯†åˆ«å‡ºå…³é”®å®ä½“å’Œæ ‡ç­¾

2. **ç¬¬2æ­¥ï¼šæŸ¥è¯¢ä½ç½®**
   - å¯¹æ¯ä¸ªè¯†åˆ«å‡ºçš„å®ä½“ï¼Œè°ƒç”¨ `get_entity_position` æŸ¥è¯¢ç°æœ‰ä½ç½®
   - è°ƒç”¨ `analyze_graph_position` åˆ†æå®ä½“çš„é‡è¦æ€§
   - äº†è§£è¿™äº›å®ä½“åœ¨å›¾ä¸­çš„ä¸Šä¸‹æ–‡

3. **ç¬¬3æ­¥ï¼šåæ€è§„åˆ’**
   - åŸºäºæŸ¥è¯¢ç»“æœï¼Œè°ƒç”¨ `suggest_relations` æ€è€ƒæ–°å®ä½“åº”è¯¥æ”¾åœ¨å“ªé‡Œ
   - å’Œè°å»ºç«‹å…³ç³»ï¼Ÿå…³ç³»ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿ
   - æ˜¯å¦éœ€è¦è¡¥å……ç°æœ‰çš„å…³è”ï¼Ÿ

4. **ç¬¬4æ­¥ï¼šæ‰§è¡Œä¿å­˜**
   - è°ƒç”¨ `save_note` ä¿å­˜ç¬”è®°
   - æ ¹æ®è§„åˆ’è¡¥å……å¿…è¦çš„å…³è”å…³ç³»

é‡è¦åŸåˆ™ï¼š
- ä¸è¦æ€¥äºä¿å­˜ï¼Œå…ˆäº†è§£æƒ…å†µ
- æ¯æ¬¡åªå¤„ç†ä¸€ä¸ªä»»åŠ¡
- å¦‚æœå‘ç°é—®é¢˜ï¼ŒåŠæ—¶è°ƒæ•´è®¡åˆ’
- ç”¨ä¸­æ–‡å›å¤ï¼Œè§£é‡Šä½ çš„æ€è€ƒè¿‡ç¨‹

ä½ çš„å›åº”åº”è¯¥åŒ…å«ï¼š
- ä½ æ­£åœ¨åšä»€ä¹ˆï¼ˆåˆ†æ/æŸ¥è¯¢/åæ€/æ‰§è¡Œï¼‰
- ä½ å‘ç°äº†ä»€ä¹ˆ
- ä½ æ‰“ç®—æ€ä¹ˆåš
"""

        self.graph = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt=self.system_prompt
        )

    def chat(self, user_input: str) -> str:
        """
        ä¸ Agent å¯¹è¯
        """
        try:
            inputs = {"messages": [{"role": "user", "content": user_input}]}
            final_state = self.graph.invoke(inputs)

            messages = final_state.get("messages", [])
            if messages:
                last_message = messages[-1]
                return last_message.content
            return "Agent æ²¡æœ‰å›åº”ã€‚"

        except Exception as e:
            return f"âŒ Agent è¿è¡Œå‡ºé”™: {e}"


class PlannerThenExecutor:
    """
    è§„åˆ’å™¨-æ‰§è¡Œå™¨åˆ†ç¦»æ¨¡å¼
    æ›´æ¸…æ™°åœ°å±•ç¤º"å…ˆè§„åˆ’åæ‰§è¡Œ"çš„å·¥ä½œæµ
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            model=config.LLM_MODEL,
            api_key=config.LLM_API_KEY,
            base_url=config.LLM_BASE_URL,
            temperature=0.3,
        )

    def plan(self, content: str) -> Dict:
        """
        è§„åˆ’é˜¶æ®µï¼šåˆ†æå¹¶åˆ¶å®šä¿å­˜è®¡åˆ’

        Args:
            content: è¦ä¿å­˜çš„ç¬”è®°å†…å®¹

        Returns:
            åŒ…å«åˆ†æç»“æœçš„å­—å…¸
        """
        from langchain_core.messages import HumanMessage
        from langchain_core.prompts import ChatPromptTemplate

        messages = [
            ("system", "åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œæå–å…³é”®å®ä½“ï¼ˆäººåã€æŠ€æœ¯åè¯ã€åœ°ç‚¹ç­‰ï¼‰å’Œæ ‡ç­¾ï¼ˆä¸»é¢˜åˆ†ç±»ï¼‰ã€‚ç”¨ä¸­æ–‡å›å¤ã€‚"),
            ("human", f"æ–‡æœ¬å†…å®¹ï¼š\n{content}")
        ]

        prompt = ChatPromptTemplate.from_messages(messages)
        response = self.llm.invoke(prompt.format_messages())
        entities_analysis = response.content if hasattr(response, 'content') else str(response)

        return {
            "content": content,
            "entities_analysis": entities_analysis,
            "status": "planned"
        }

    def analyze_positions(self, plan: Dict) -> Dict:
        """
        åˆ†æé˜¶æ®µï¼šæŸ¥è¯¢å®ä½“çš„ç°æœ‰ä½ç½®

        Args:
            plan: è§„åˆ’é˜¶æ®µçš„ç»“æœ

        Returns:
            åŒ…å«ä½ç½®åˆ†æç»“æœçš„å­—å…¸
        """
        import re

        content = plan["content"]
        entities = []
        noise_entities = []

        # 1. æå–æŠ€æœ¯å…³é”®è¯ï¼ˆè¿™æ˜¯æ ¸å¿ƒå®ä½“ï¼‰
        tech_keywords = [
            'Python', 'JavaScript', 'Java', 'Go', 'Rust', 'C++', 'TypeScript',
            'React', 'Vue', 'Angular', 'Node.js', 'Django', 'Flask', 'Spring',
            'LangChain', 'OpenAI', 'Neo4j', 'PostgreSQL', 'MongoDB', 'Redis',
            'Docker', 'Kubernetes', 'AWS', 'Azure', 'GCP', 'AI', 'LLM',
            'ChatGPT', 'TensorFlow', 'PyTorch', 'FastAPI', 'GraphQL',
            'æ•°æ®åˆ†æ', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç¥ç»ç½‘ç»œ', 'å¤§è¯­è¨€æ¨¡å‹'
        ]

        for kw in tech_keywords:
            if kw.lower() in content.lower():
                if kw not in entities:
                    entities.append(kw)

        # 2. æå–æœ‰æ„ä¹‰çš„è¯ç»„ï¼ˆ3-5ä¸ªå­—çš„å®Œæ•´æ¦‚å¿µï¼‰
        meaningful_phrases = [
            'ç¼–ç¨‹è¯­è¨€', 'ç³»ç»Ÿç¼–ç¨‹', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'è‡ªç„¶è¯­è¨€å¤„ç†',
            'å›¾æ•°æ®åº“', 'å…³ç³»å‹æ•°æ®åº“', 'å¾®æœåŠ¡æ¶æ„', 'å‰åç«¯åˆ†ç¦»',
            'çŸ¥è¯†å›¾è°±', 'å‘é‡æ•°æ®åº“', 'å®¹å™¨ç¼–æ’', 'æŒç»­é›†æˆ'
        ]

        for phrase in meaningful_phrases:
            if phrase in content and phrase not in entities:
                entities.append(phrase)

        # 3. æå–ä¸­æ–‡å®ä½“ï¼ˆåªä¿ç•™çœŸæ­£æœ‰æ„ä¹‰çš„ï¼‰
        # å¸¸è§æ— æ„ä¹‰è¯æ±‡åˆ—è¡¨
        stop_words = set([
            'ä¸€ä¸ª', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'å¦‚ä½•', 'å¯ä»¥', 'åº”è¯¥', 'ç„¶å',
            'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯', 'è€Œä¸”', 'æˆ–è€…', 'å¦‚æœ', 'è™½ç„¶', 'åªæ˜¯',
            'è¿˜æœ‰', 'å°±æ˜¯', 'ä¸æ˜¯', 'è‡ªå·±', 'ç°åœ¨', 'å·²ç»', 'å¼€å§‹',
            'ç”¨äº', 'é€‚åˆ', 'ä¸»è¦', 'æœ€è¿‘', 'ä»Šå¤©', 'æ˜¨å¤©', 'æ˜å¤©',
            'å­¦ä¹ ', 'äº†è§£', 'å‘ç°', 'ä½¿ç”¨', 'å‚è€ƒ', 'æ‰“ç®—', 'åˆ›å»º',
            'ä¸€é—¨', 'ç”¨äº', 'éå¸¸', 'ä¸€èµ·', 'ä¸€èµ·', 'ä¸œè¥¿', 'æœ€è¿‘'
        ])

        # åªæå–4-5ä¸ªå­—çš„å®Œæ•´æ¦‚å¿µ
        chinese_concepts = re.findall(r'[\u4e00-\u9fa5]{4,6}', content)
        for concept in chinese_concepts:
            # è¿‡æ»¤æ‰åŒ…å«åœç”¨è¯çš„
            is_noise = False
            for stop in stop_words:
                if stop in concept:
                    is_noise = True
                    break
            # è¿‡æ»¤æ‰çº¯æ•°å­—æˆ–çº¯æ ‡ç‚¹çš„
            if re.match(r'^[\d\sï¼Œã€‚ï¼ï¼Ÿ]+$', concept):
                is_noise = True
            
            if not is_noise and concept not in entities and len(concept) >= 3:
                entities.append(concept)

        # 4. åªä¿ç•™æ ¸å¿ƒå®ä½“ï¼ˆæœ€å¤š5ä¸ªï¼‰ï¼Œå…¶ä»–ä½œä¸ºå™ªéŸ³
        core_entities = []
        for e in entities:
            # ä¿ç•™æŠ€æœ¯å…³é”®è¯å’Œå®Œæ•´æ¦‚å¿µ
            is_core = any(kw.lower() == e.lower() for kw in tech_keywords)
            is_concept = any(phrase == e for phrase in meaningful_phrases)
            if is_core or is_concept:
                core_entities.append(e)

        final_entities = core_entities if core_entities else entities[:3]
        
        # æŸ¥è¯¢æ¯ä¸ªæ ¸å¿ƒå®ä½“çš„ä½ç½®
        positions = {}
        for entity in final_entities[:5]:
            result = get_entity_position.invoke({"entity_name": entity})
            positions[entity] = result

        return {
            "content": plan["content"],
            "entities_analysis": plan["entities_analysis"],
            "entities": final_entities,
            "positions": positions,
            "status": "analyzed"
        }

    def reflect(self, analysis: Dict) -> Dict:
        """
        åæ€é˜¶æ®µï¼šåŸºäºåˆ†æç»“æœï¼Œåˆ¶å®šå…·ä½“è¡ŒåŠ¨è®¡åˆ’

        Args:
            analysis: åˆ†æé˜¶æ®µçš„ç»“æœ

        Returns:
            åŒ…å«è¡ŒåŠ¨è®¡åˆ’çš„ç»“æœ
        """
        from langchain_core.prompts import ChatPromptTemplate

        content = analysis["content"]
        entities = analysis["entities"]
        positions = analysis["positions"]

        content_text = analysis["content"]
        entities_list = analysis["entities"]
        positions_dict = analysis["positions"]

        entities_str = ', '.join(entities_list) if entities_list else 'æ–°å®ä½“'
        
        positions_text = []
        for entity, pos in positions_dict.items():
            positions_text.append(f"ã€{entity}ã€‘{pos}")
        positions_str = '\n'.join(positions_text) if positions_text else 'æš‚æ— ç°æœ‰å…³è”'

        messages = [
            ("system", "ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†å›¾è°±è§„åˆ’ä¸“å®¶ã€‚æ ¹æ®ä»¥ä¸‹åˆ†æç»“æœï¼Œåˆ¶å®šå…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’ã€‚ç”¨ä¸­æ–‡å›å¤ï¼Œæ¡ç†æ¸…æ™°ã€‚"),
            ("human", f"ã€æ–‡æœ¬å†…å®¹ã€‘\n{content_text}\n\nã€æå–çš„å®ä½“ã€‘\n{entities_str}\n\nã€å®ä½“ä½ç½®åˆ†æã€‘\n{positions_str}")
        ]

        prompt = ChatPromptTemplate.from_messages(messages)
        response = self.llm.invoke(prompt.format_messages())
        action_plan = response.content if hasattr(response, 'content') else str(response)

        return {
            "content": content,
            "entities_analysis": analysis["entities_analysis"],
            "entities": entities,
            "positions": positions,
            "action_plan": action_plan,
            "status": "reflected"
        }

    def execute(self, reflection: Dict) -> Dict:
        """
        æ‰§è¡Œé˜¶æ®µï¼šæ ¹æ®è¡ŒåŠ¨è®¡åˆ’ä¿å­˜ç¬”è®°

        Args:
            reflection: åæ€é˜¶æ®µçš„ç»“æœ

        Returns:
            æ‰§è¡Œç»“æœ
        """
        content = reflection["content"]
        entities = reflection["entities"]
        action_plan = reflection["action_plan"]

        # æå–æ ‡ç­¾
        tags = []
        if "ç¼–ç¨‹" in content or "ä»£ç " in content:
            tags.append("ç¼–ç¨‹")
        if "AI" in content or "æ¨¡å‹" in content:
            tags.append("AI")
        if "æ•°æ®åº“" in content or "å­˜å‚¨" in content:
            tags.append("æ•°æ®åº“")
        if not tags:
            tags = ["é€šç”¨"]

        # è°ƒç”¨ save_note ä¿å­˜
        result = save_note.invoke({
            "content": content,
            "entities": entities,
            "tags": tags
        })

        # è¡¥å……å…³ç³»ï¼ˆåªå¯¹æ ¸å¿ƒæœ‰æ„ä¹‰å®ä½“å»ºç«‹å…³ç³»ï¼‰
        relations_added = []
        meaningful_entities = [e for e in entities if len(e) >= 3 and not any(c in e for c in ['çš„', 'æ˜¯', 'äº†', 'åœ¨', 'å’Œ', 'ä¸'])]
        
        if len(meaningful_entities) > 1:
            # åªåˆ›å»ºå‰5ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»
            for i in range(min(len(meaningful_entities), 5)):
                for j in range(i + 1, min(len(meaningful_entities), 5)):
                    e1, e2 = meaningful_entities[i], meaningful_entities[j]
                    
                    # åªå»ºç«‹æœ‰æ„ä¹‰çš„å…³ç³»ï¼ˆé¿å…å™ªéŸ³ï¼‰
                    if len(e1) > 2 and len(e2) > 2:
                        rel_result = execute_raw_cypher.invoke({
                            "query": """
                            MERGE (e1:Entity {name: $e1})
                            MERGE (e2:Entity {name: $e2})
                            MERGE (e1)-[:RELATED_TO]->(e2)
                            """,
                            "params": {"e1": e1, "e2": e2}
                        })
                        relations_added.append(f"{e1} <-> {e2}")

        return {
            "content": content,
            "entities": entities,
            "tags": tags,
            "save_result": result,
            "relations_added": relations_added,
            "action_plan": action_plan,
            "status": "executed"
        }

    def smart_save(self, content: str) -> str:
        """
        å®Œæ•´çš„æ™ºèƒ½ä¿å­˜æµç¨‹ï¼ˆå…ˆè§„åˆ’åæ‰§è¡Œï¼‰

        Args:
            content: è¦ä¿å­˜çš„ç¬”è®°å†…å®¹

        Returns:
            å®Œæ•´çš„æ‰§è¡ŒæŠ¥å‘Š
        """
        report = ["ğŸ§  **æ™ºèƒ½ä¿å­˜æµç¨‹å¼€å§‹**\n"]

        # Step 1: è§„åˆ’
        plan = self.plan(content)
        report.append("ğŸ“‹ **ç¬¬1æ­¥ï¼šè§„åˆ’**")
        report.append(f"  æå–çš„å®ä½“åˆ†æï¼š\n  {plan['entities_analysis']}\n")

        # Step 2: åˆ†æä½ç½®
        analysis = self.analyze_positions(plan)
        report.append("ğŸ” **ç¬¬2æ­¥ï¼šåˆ†æç°æœ‰ä½ç½®**")
        if analysis["entities"]:
            report.append(f"  å‘ç° {len(analysis['entities'])} ä¸ªå®ä½“ï¼š")
            for entity, position in analysis["positions"].items():
                report.append(f"\n  ğŸ“Œ {entity}:")
                report.append(f"     {position[:100]}..." if len(position) > 100 else f"     {position}")
        else:
            report.append("  éƒ½æ˜¯æ–°å®ä½“ï¼Œæš‚æ— ç°æœ‰å…³è”")
        report.append("")

        # Step 3: åæ€
        reflection = self.reflect(analysis)
        report.append("ğŸ’­ **ç¬¬3æ­¥ï¼šåæ€ä¸è§„åˆ’**")
        report.append(f"  è¡ŒåŠ¨è®¡åˆ’ï¼š\n  {reflection['action_plan']}\n")

        # Step 4: æ‰§è¡Œ
        execution = self.execute(reflection)
        report.append("âœ… **ç¬¬4æ­¥ï¼šæ‰§è¡Œä¿å­˜**")
        report.append(f"  ä¿å­˜ç»“æœï¼š{execution['save_result']}")
        if execution['relations_added']:
            report.append(f"\n  è¡¥å……å…³ç³»ï¼š")
            for rel in execution['relations_added']:
                report.append(f"    â€¢ {rel}")

        return "\n".join(report)


smart_note_agent = SmartNoteAgent()
smart_planner = PlannerThenExecutor()


def smart_save(content: str) -> str:
    """
    æ™ºèƒ½ä¿å­˜ç¬”è®°ï¼ˆå…¥å£å‡½æ•°ï¼‰

    Args:
        content: ç¬”è®°å†…å®¹

    Returns:
        æ‰§è¡ŒæŠ¥å‘Š
    """
    return smart_planner.smart_save(content)
