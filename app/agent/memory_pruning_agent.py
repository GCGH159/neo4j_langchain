"""
è®°å¿†è£å‰ª Agent - è´Ÿè´£æ•´ç†å’Œä¼˜åŒ– Neo4j å›¾è°±ä¸­çš„è®°å¿†
"""
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain_core.tools import tool
from app.core.graph import execute_cypher
from config import config
from pydantic import SecretStr


# ==================== è®°å¿†è£å‰ªå·¥å…·é›† ====================

@tool
def analyze_memory_graph() -> str:
    """
    åˆ†æå½“å‰è®°å¿†å›¾è°±çš„çŠ¶æ€ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹æ•°é‡ã€å…³ç³»å¯†åº¦ã€å†—ä½™ä¿¡æ¯ç­‰ã€‚
    
    Returns:
        å›¾è°±åˆ†ææŠ¥å‘Š
    """
    query = """
    // ç»Ÿè®¡å„ç±»èŠ‚ç‚¹æ•°é‡
    MATCH (n)
    WITH labels(n) as label_list, count(n) as node_count
    UNWIND label_list as label
    WITH label, sum(node_count) as count
    WHERE count > 0
    RETURN label, count
    ORDER BY count DESC
    """
    node_stats = execute_cypher(query)
    
    # ç»Ÿè®¡å…³ç³»
    rel_query = """
    MATCH ()-[r]->()
    RETURN type(r) as rel_type, count(r) as count
    ORDER BY count DESC
    """
    rel_stats = execute_cypher(rel_query)
    
    # æŸ¥æ‰¾å­¤ç«‹èŠ‚ç‚¹
    orphan_query = """
    MATCH (n)
    WHERE NOT (n)-[]-()
    RETURN labels(n)[0] as label, count(n) as orphan_count
    """
    orphan_stats = execute_cypher(orphan_query)
    
    report = ["ğŸ“Š è®°å¿†å›¾è°±åˆ†ææŠ¥å‘Š\n"]
    report.append("èŠ‚ç‚¹ç»Ÿè®¡:")
    for stat in node_stats:
        report.append(f"  â€¢ {stat['label']}: {stat['count']} ä¸ª")
    
    report.append("\nå…³ç³»ç»Ÿè®¡:")
    for stat in rel_stats:
        report.append(f"  â€¢ {stat['rel_type']}: {stat['count']} æ¡")
    
    if orphan_stats and any(s['orphan_count'] > 0 for s in orphan_stats):
        report.append("\nâš ï¸  å‘ç°å­¤ç«‹èŠ‚ç‚¹:")
        for stat in orphan_stats:
            if stat['orphan_count'] > 0:
                report.append(f"  â€¢ {stat['label']}: {stat['orphan_count']} ä¸ª")
    
    return "\n".join(report)


@tool
def find_redundant_entities() -> str:
    """
    æŸ¥æ‰¾å†—ä½™çš„å®ä½“èŠ‚ç‚¹ï¼ˆåç§°ç›¸ä¼¼ã€å…³ç³»ç›¸åŒçš„å®ä½“ï¼‰ã€‚
    
    Returns:
        å†—ä½™å®ä½“åˆ—è¡¨
    """
    query = """
    // æŸ¥æ‰¾åç§°éå¸¸ç›¸ä¼¼çš„å®ä½“
    MATCH (e1:Entity), (e2:Entity)
    WHERE e1.name < e2.name
      AND (
        toLower(e1.name) = toLower(e2.name) OR
        e1.name CONTAINS e2.name OR
        e2.name CONTAINS e1.name
      )
    RETURN e1.name as name1, e2.name as name2
    LIMIT 20
    """
    results = execute_cypher(query)
    
    if not results:
        return "âœ… æœªå‘ç°æ˜æ˜¾çš„å†—ä½™å®ä½“"
    
    report = ["âš ï¸  å‘ç°å¯èƒ½å†—ä½™çš„å®ä½“:"]
    for r in results:
        report.append(f"  â€¢ '{r['name1']}' â†”ï¸ '{r['name2']}'")
    
    return "\n".join(report)


@tool
def merge_similar_entities(entity1: str, entity2: str, keep_name: str) -> str:
    """
    åˆå¹¶ä¸¤ä¸ªç›¸ä¼¼çš„å®ä½“èŠ‚ç‚¹ï¼Œä¿ç•™æŒ‡å®šåç§°çš„å®ä½“ã€‚
    
    Args:
        entity1: ç¬¬ä¸€ä¸ªå®ä½“åç§°
        entity2: ç¬¬äºŒä¸ªå®ä½“åç§°
        keep_name: è¦ä¿ç•™çš„å®ä½“åç§°ï¼ˆå¿…é¡»æ˜¯ entity1 æˆ– entity2ï¼‰
        
    Returns:
        åˆå¹¶ç»“æœ
    """
    if keep_name not in [entity1, entity2]:
        return f"âŒ keep_name å¿…é¡»æ˜¯ '{entity1}' æˆ– '{entity2}'"
    
    remove_name = entity2 if keep_name == entity1 else entity1
    
    # ç®€åŒ–çš„åˆå¹¶é€»è¾‘ï¼šè½¬ç§»æ‰€æœ‰å…³ç³»ååˆ é™¤å†—ä½™èŠ‚ç‚¹
    query = """
    MATCH (keep:Entity {name: $keep_name})
    MATCH (remove:Entity {name: $remove_name})
    
    // å¤åˆ¶ MENTIONS å…³ç³»
    WITH keep, remove
    OPTIONAL MATCH (n:Note)-[r:MENTIONS]->(remove)
    MERGE (n)-[:MENTIONS]->(keep)
    DELETE r
    
    // åˆ é™¤å†—ä½™èŠ‚ç‚¹
    WITH keep, remove
    DETACH DELETE remove
    RETURN keep.name as kept_entity
    """
    
    try:
        execute_cypher(query, {
            "keep_name": keep_name,
            "remove_name": remove_name
        })
        return f"âœ… å·²åˆå¹¶å®ä½“: '{remove_name}' â†’ '{keep_name}'"
    except Exception as e:
        return f"âŒ åˆå¹¶å¤±è´¥: {e}"


@tool
def remove_orphan_nodes(label: str = "all") -> str:
    """
    åˆ é™¤å­¤ç«‹çš„èŠ‚ç‚¹ï¼ˆæ²¡æœ‰ä»»ä½•å…³ç³»çš„èŠ‚ç‚¹ï¼‰ã€‚
    
    Args:
        label: èŠ‚ç‚¹æ ‡ç­¾ï¼Œ"all" è¡¨ç¤ºåˆ é™¤æ‰€æœ‰ç±»å‹çš„å­¤ç«‹èŠ‚ç‚¹
        
    Returns:
        åˆ é™¤ç»“æœ
    """
    if label == "all":
        query = """
        MATCH (n)
        WHERE NOT (n)-[]-()
        DELETE n
        RETURN count(n) as deleted_count
        """
    else:
        query = f"""
        MATCH (n:`{label}`)
        WHERE NOT (n)-[]-()
        DELETE n
        RETURN count(n) as deleted_count
        """
    
    try:
        result = execute_cypher(query, {})
        count = result[0]['deleted_count'] if result else 0
        return f"âœ… å·²åˆ é™¤ {count} ä¸ªå­¤ç«‹èŠ‚ç‚¹"
    except Exception as e:
        return f"âŒ åˆ é™¤å¤±è´¥: {e}"


@tool
def prune_old_messages(session_id: str, keep_recent: int = 20) -> str:
    """
    è£å‰ªæ—§çš„å¯¹è¯æ¶ˆæ¯ï¼Œåªä¿ç•™æœ€è¿‘çš„ N æ¡ã€‚
    
    Args:
        session_id: ä¼šè¯ID
        keep_recent: è¦ä¿ç•™çš„æœ€è¿‘æ¶ˆæ¯æ•°é‡
        
    Returns:
        è£å‰ªç»“æœ
    """
    query = """
    MATCH (s:Session {id: $session_id})-[:HAS_MESSAGE]->(m:Message)
    WITH m
    ORDER BY m.timestamp DESC
    SKIP $keep_recent
    DETACH DELETE m
    RETURN count(m) as deleted_count
    """
    
    try:
        result = execute_cypher(query, {
            "session_id": session_id,
            "keep_recent": keep_recent
        })
        count = result[0]['deleted_count'] if result else 0
        return f"âœ… å·²åˆ é™¤ä¼šè¯ '{session_id}' çš„ {count} æ¡æ—§æ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘ {keep_recent} æ¡"
    except Exception as e:
        return f"âŒ è£å‰ªå¤±è´¥: {e}"


@tool
def consolidate_notes_by_topic(topic_keyword: str, new_summary: str) -> str:
    """
    å°†æŸä¸ªä¸»é¢˜çš„å¤šæ¡ç¬”è®°åˆå¹¶ä¸ºä¸€æ¡æ‘˜è¦ç¬”è®°ã€‚
    
    Args:
        topic_keyword: ä¸»é¢˜å…³é”®è¯ï¼ˆç”¨äºæœç´¢ç›¸å…³ç¬”è®°ï¼‰
        new_summary: æ–°çš„æ‘˜è¦å†…å®¹
        
    Returns:
        åˆå¹¶ç»“æœ
    """
    # æŸ¥æ‰¾ç›¸å…³ç¬”è®°
    search_query = """
    MATCH (n:Note)
    WHERE n.content CONTAINS $keyword
    RETURN n.id as note_id, n.content as content
    """
    notes = execute_cypher(search_query, {"keyword": topic_keyword})
    
    if not notes:
        return f"æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ '{topic_keyword}' çš„ç¬”è®°"
    
    # åˆ›å»ºæ–°çš„æ‘˜è¦ç¬”è®°
    from datetime import datetime
    import uuid
    
    create_query = """
    CREATE (summary:Note {
        id: $id,
        content: $content,
        created_at: $timestamp,
        type: 'summary'
    })
    RETURN summary.id as new_id
    """
    
    new_id = str(uuid.uuid4())
    execute_cypher(create_query, {
        "id": new_id,
        "content": new_summary,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    })
    
    # å°†åŸç¬”è®°çš„å…³ç³»è½¬ç§»åˆ°æ‘˜è¦ç¬”è®°
    transfer_query = """
    MATCH (old:Note)
    WHERE old.id IN $old_ids
    MATCH (summary:Note {id: $new_id})
    
    OPTIONAL MATCH (old)-[:MENTIONS]->(e:Entity)
    MERGE (summary)-[:MENTIONS]->(e)
    
    OPTIONAL MATCH (old)-[:HAS_TAG]->(t:Tag)
    MERGE (summary)-[:HAS_TAG]->(t)
    
    WITH old, summary
    DETACH DELETE old
    """
    
    old_ids = [n['note_id'] for n in notes]
    execute_cypher(transfer_query, {"old_ids": old_ids, "new_id": new_id})
    
    return f"âœ… å·²å°† {len(notes)} æ¡ç¬”è®°åˆå¹¶ä¸ºæ‘˜è¦ç¬”è®°ï¼ˆID: {new_id[:8]}...ï¼‰"


# ==================== è®°å¿†è£å‰ª Agent ====================

class MemoryPruningAgent:
    """
    è®°å¿†è£å‰ª Agent
    è´Ÿè´£åˆ†æå’Œä¼˜åŒ– Neo4j å›¾è°±ä¸­çš„è®°å¿†ç»“æ„
    """
    
    def __init__(self):
        # 1. åˆå§‹åŒ– LLM
        self.llm = ChatOpenAI(
            model=config.LLM_MODEL,
            api_key=SecretStr(config.LLM_API_KEY) if config.LLM_API_KEY else None,
            base_url=config.LLM_BASE_URL,
            temperature=0.3,  # è¾ƒä½æ¸©åº¦ä»¥ä¿æŒä¸€è‡´æ€§
        )
        
        # 2. å®šä¹‰å·¥å…·é›†
        self.tools = [
            analyze_memory_graph,
            find_redundant_entities,
            merge_similar_entities,
            remove_orphan_nodes,
            prune_old_messages,
            consolidate_notes_by_topic
        ]
        
        # 3. åˆ›å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªè®°å¿†æ•´ç†ä¸“å®¶ï¼Œè´Ÿè´£ä¼˜åŒ–å’Œç»´æŠ¤ Neo4j çŸ¥è¯†å›¾è°±ã€‚

ä½ çš„èŒè´£ï¼š
1. **åˆ†æå›¾è°±çŠ¶æ€**ï¼šå®šæœŸåˆ†æå›¾è°±çš„èŠ‚ç‚¹ã€å…³ç³»ã€å†—ä½™ä¿¡æ¯
2. **è¯†åˆ«ä¼˜åŒ–æœºä¼š**ï¼š
   - æŸ¥æ‰¾ç›¸ä¼¼æˆ–å†—ä½™çš„å®ä½“èŠ‚ç‚¹
   - è¯†åˆ«å­¤ç«‹çš„ã€æ— å…³è”çš„èŠ‚ç‚¹
   - å‘ç°å¯ä»¥åˆå¹¶çš„ç›¸å…³ç¬”è®°
3. **æ‰§è¡Œä¼˜åŒ–æ“ä½œ**ï¼š
   - åˆå¹¶ç›¸ä¼¼å®ä½“
   - åˆ é™¤æ— ç”¨çš„å­¤ç«‹èŠ‚ç‚¹
   - è£å‰ªè¿‡æœŸçš„å¯¹è¯å†å²
   - å°†å¤šæ¡ç›¸å…³ç¬”è®°æ•´åˆä¸ºæ‘˜è¦
4. **æ±‡æŠ¥ç»“æœ**ï¼šæ¸…æ™°è¯´æ˜æ‰§è¡Œäº†ä»€ä¹ˆæ“ä½œï¼Œäº§ç”Ÿäº†ä»€ä¹ˆæ•ˆæœ

ä¼˜åŒ–åŸåˆ™ï¼š
- ä¿å®ˆä¸ºä¸»ï¼šä¸ç¡®å®šæ—¶ä¸è¦åˆ é™¤æ•°æ®
- å…ˆåˆ†æåæ“ä½œï¼šäº†è§£æƒ…å†µåå†å†³å®šå¦‚ä½•ä¼˜åŒ–
- ä¿ç•™é‡è¦ä¿¡æ¯ï¼šåˆ é™¤å†—ä½™ä½†ä¿ç•™æ ¸å¿ƒå†…å®¹
- ç”¨æˆ·ç¡®è®¤ï¼šé‡å¤§æ“ä½œå‰å‘ç”¨æˆ·ç¡®è®¤

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œæ“ä½œå®Œæˆåæä¾›è¯¦ç»†æŠ¥å‘Šã€‚
"""
        
        # 4. åˆ›å»º Agent
        self.graph = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt=system_prompt
        )
    
    def optimize(self, instruction: str = "è¯·åˆ†æè®°å¿†å›¾è°±å¹¶æä¾›ä¼˜åŒ–å»ºè®®") -> str:
        """
        æ‰§è¡Œè®°å¿†ä¼˜åŒ–æ“ä½œ
        
        Args:
            instruction: ä¼˜åŒ–æŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼š"åˆ†æå¹¶åˆ é™¤å­¤ç«‹èŠ‚ç‚¹"ï¼‰
            
        Returns:
            ä¼˜åŒ–ç»“æœæŠ¥å‘Š
        """
        try:
            inputs = {"messages": [{"role": "user", "content": instruction}]}
            final_state = self.graph.invoke(inputs)
            
            messages = final_state.get("messages", [])
            if messages:
                last_message = messages[-1]
                return last_message.content
            return "Agent æ²¡æœ‰å›åº”ã€‚"
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            return f"âŒ ä¼˜åŒ–æ“ä½œå‡ºé”™: {e}\nè¯¦ç»†ä¿¡æ¯:\n{error_details}"


# å•ä¾‹å®ä¾‹
memory_pruning_agent = MemoryPruningAgent()
